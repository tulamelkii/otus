Install Vagrant 
Create Vagrantfile and edit (*see Vagrant)
Download machines from repository Vagrant "tulamelkii/VDebian12"
Enter vagrant up and vagrant provision
Outpoot Raid-10 and create gpt with 4 partition 
Check array
------------------------------------------------------------------
vagrant@VDebian:~$ lsblk
NAME      MAJ:MIN RM  SIZE RO TYPE   MOUNTPOINTS
sda         8:0    0 24.4G  0 disk   
├─sda1      8:1    0  4.9G  0 part   /
├─sda2      8:2    0    1K  0 part   
├─sda5      8:5    0    2G  0 part   /var
├─sda6      8:6    0  976M  0 part   [SWAP]
├─sda7      8:7    0  418M  0 part   /tmp
└─sda8      8:8    0 16.2G  0 part   /home
sdb         8:16   0  500M  0 disk   
└─md0       9:0    0  996M  0 raid10 
  ├─md0p1 259:2    0  248M  0 part   /raid/part1
  ├─md0p2 259:3    0  249M  0 part   /raid/part2
  ├─md0p3 259:6    0  249M  0 part   /raid/part3
  └─md0p4 259:7    0  248M  0 part   /raid/part4
sdc         8:32   0  500M  0 disk   
└─md0       9:0    0  996M  0 raid10 
  ├─md0p1 259:2    0  248M  0 part   /raid/part1
  ├─md0p2 259:3    0  249M  0 part   /raid/part2
  ├─md0p3 259:6    0  249M  0 part   /raid/part3
  └─md0p4 259:7    0  248M  0 part   /raid/part4
sdd         8:48   0  500M  0 disk   
└─md0       9:0    0  996M  0 raid10 
  ├─md0p1 259:2    0  248M  0 part   /raid/part1
  ├─md0p2 259:3    0  249M  0 part   /raid/part2
  ├─md0p3 259:6    0  249M  0 part   /raid/part3
  └─md0p4 259:7    0  248M  0 part   /raid/part4
sde         8:64   0  500M  0 disk   
└─md0       9:0    0  996M  0 raid10 
  ├─md0p1 259:2    0  248M  0 part   /raid/part1
  ├─md0p2 259:3    0  249M  0 part   /raid/part2
  ├─md0p3 259:6    0  249M  0 part   /raid/part3
  └─md0p4 259:7    0  248M  0 part   /raid/part4
  ------------------------------------------------------------------
 vagrant@VDebian:~$ sudo mdadm -D /dev/md0
/dev/md0:
           Version : 1.2
     Creation Time : Mon May 15 19:45:09 2023
        Raid Level : raid10
        Array Size : 1019904 (996.00 MiB 1044.38 MB)
     Used Dev Size : 509952 (498.00 MiB 522.19 MB)
      Raid Devices : 4
     Total Devices : 4
       Persistence : Superblock is persistent

       Update Time : Mon May 15 19:45:52 2023
             State : clean 
    Active Devices : 4
   Working Devices : 4
    Failed Devices : 0
     Spare Devices : 0

            Layout : near=2
        Chunk Size : 512K

Consistency Policy : resync

              Name : VDebian:0  (local to host VDebian)
              UUID : 7a4d098d:b449db97:a9bb8c95:70e92214
            Events : 21

    Number   Major   Minor   RaidDevice State
       0       8       16        0      active sync set-A   /dev/sdb
       1       8       32        1      active sync set-B   /dev/sdc
       2       8       48        2      active sync set-A   /dev/sdd
       3       8       64        3      active sync set-B   /dev/sde
----------------------------------------------------------------------
vagrant@VDebian:~$ cat /proc/mdstat
Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] 
md0 : active raid10 sde[3] sdd[2] sdc[1] sdb[0]
      1019904 blocks super 1.2 512K chunks 2 near-copies [4/4] [UUUU]
      
unused devices: <none>
----------------------------------------------------------------------
agrant@VDebian:~$ sudo mdadm --detail --scan --verbose
ARRAY /dev/md0 level=raid10 num-devices=4 metadata=1.2 name=VDebian:0 UUID=7a4d098d:b449db97:a9bb8c95:70e92214
   devices=/dev/sdb,/dev/sdc,/dev/sdd,/dev/sde
----------------------------------------------------------------------   
Fail disk and Remove
----------------------------------------------------------------------
vagrant@VDebian:~$ sudo mdadm /dev/md0 -f /dev/sdd
mdadm: set /dev/sdd faulty in /dev/md0
vagrant@VDebian:~$ sudo mdadm /dev/md0 -r /dev/sdd
vagrant@VDebian:~$ cat /proc/mdstat 
Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] 
md0 : active raid10 sde[3] sdd[2](F) sdc[1] sdb[0]
      1019904 blocks super 1.2 512K chunks 2 near-copies [4/3] [UU_U]
      
unused devices: <none>
-------------------------------------------------------------------------
vagrant@VDebian:~$ sudo mdadm -D /dev/md0
/dev/md0:
           Version : 1.2
     Creation Time : Mon May 15 19:45:09 2023
        Raid Level : raid10
        Array Size : 1019904 (996.00 MiB 1044.38 MB)
     Used Dev Size : 509952 (498.00 MiB 522.19 MB)
      Raid Devices : 4
     Total Devices : 4
       Persistence : Superblock is persistent

       Update Time : Mon May 15 20:18:50 2023
             State : clean, degraded 
    Active Devices : 3
   Working Devices : 3
    Failed Devices : 1
     Spare Devices : 0

            Layout : near=2
        Chunk Size : 512K

Consistency Policy : resync

              Name : VDebian:0  (local to host VDebian)
              UUID : 7a4d098d:b449db97:a9bb8c95:70e92214
            Events : 23

    Number   Major   Minor   RaidDevice State
       0       8       16        0      active sync set-A   /dev/sdb
       1       8       32        1      active sync set-B   /dev/sdc
       -       0        0        2      removed
       3       8       64        3      active sync set-B   /dev/sde

       2       8       48        -      faulty   /dev/sdd
 -------------------------------------------------------------------------------
vagrant@VDebian:~$ sudo mdadm /dev/md0 --re-add /dev/sdd
mdadm: re-add /dev/sdd to md0 succeed
---------------------------------------------------------------------------------
onsistency Policy : resync

              Name : VDebian:0  (local to host VDebian)
              UUID : 7a4d098d:b449db97:a9bb8c95:70e92214
            Events : 27

    Number   Major   Minor   RaidDevice State
       0       8       16        0      active sync set-A   /dev/sdb
       1       8       32        1      active sync set-B   /dev/sdc
       2       8       48        2      active sync set-A   /dev/sdd
       3       8       64        3      active sync set-B   /dev/sde
---------------------------------------------------------------------------------
end)

